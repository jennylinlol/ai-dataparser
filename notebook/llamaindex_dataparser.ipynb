{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.program.openai import OpenAIPydanticProgram\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Define Pydantic model for structured output\n",
    "class CallAnalysis(BaseModel):\n",
    "    \"\"\"Analysis results for a customer service call transcript.\"\"\"\n",
    "    transcript_summary: str = Field(description=\"Summary of the call transcript in 2-4 sentences\")\n",
    "    call_intent: str = Field(description=\"Main purpose or intention of the call\")\n",
    "    agents_performance_rating: int = Field(ge=1, le=5, description=\"Agent performance rating (1-5)\")\n",
    "    agents_performance_rating_rationale: str = Field(description=\"Rationale for agent performance rating\")\n",
    "    customer_sentiment_rating: int = Field(ge=1, le=5, description=\"Customer sentiment rating (1-5)\")\n",
    "    customer_sentiment_rationale: str = Field(description=\"Rationale for customer sentiment rating\")\n",
    "\n",
    "def process_single_transcript_llamaindex(row, program):\n",
    "    \"\"\"Process a single transcript row using LlamaIndex\"\"\"\n",
    "    conversation_id = row['conversation_id']\n",
    "    call_transcript = row['call_transcript']\n",
    "    \n",
    "    try:\n",
    "        # Get structured response using LlamaIndex program\n",
    "        result = program(call_transcript=call_transcript)\n",
    "        \n",
    "        # Create output row\n",
    "        output_row = {\n",
    "            'conversation_id': conversation_id,\n",
    "            'call_transcript': call_transcript,\n",
    "            'transcript_summary': result.transcript_summary,\n",
    "            'call_intent': result.call_intent,\n",
    "            'agents_performance_rating': result.agents_performance_rating,\n",
    "            'agents_performance_rating_rationale': result.agents_performance_rating_rationale,\n",
    "            'customer_sentiment_rating': result.customer_sentiment_rating,\n",
    "            'customer_sentiment_rationale': result.customer_sentiment_rationale,\n",
    "            'processed_at': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Processed conversation {conversation_id}\")\n",
    "        return output_row, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_row = {\n",
    "            'conversation_id': conversation_id,\n",
    "            'error_message': str(e),\n",
    "            'error_type': type(e).__name__,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        print(f\"‚ùå Error processing conversation {conversation_id}: {e}\")\n",
    "        return None, error_row\n",
    "\n",
    "def parse_csv_with_llamaindex(input_csv: str, output_csv: str, error_csv: str, max_workers: int = 3):\n",
    "    \"\"\"\n",
    "    Parse CSV with LlamaIndex using structured outputs and concurrency\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to input CSV file\n",
    "        output_csv: Path to output CSV file  \n",
    "        error_csv: Path to error log CSV file\n",
    "        max_workers: Number of concurrent workers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define prompt template\n",
    "    prompt_template_str = \"\"\"\n",
    "    You are an AI that analyzes call transcripts between customers and agents.\n",
    "    \n",
    "    Analyze the following call transcript and extract:\n",
    "    - A 2-4 sentence summary of the call\n",
    "    - The main intent/purpose of the call\n",
    "    - Agent performance rating (1=very poor, 5=excellent)\n",
    "    - Rationale for agent rating\n",
    "    - Customer sentiment rating (1=very negative, 5=very positive)  \n",
    "    - Rationale for sentiment rating\n",
    "    \n",
    "    Call Transcript:\n",
    "    {call_transcript}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create OpenAI Pydantic Program\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        output_cls=CallAnalysis,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Read CSV with proper handling of quotes and line breaks\n",
    "        df = pd.read_csv(input_csv, quotechar='\"', escapechar='\\\\')\n",
    "        print(f\"üìä Loaded {len(df)} transcripts to process\")\n",
    "        \n",
    "        # Process transcripts concurrently\n",
    "        successful_results = []\n",
    "        error_results = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            futures = [\n",
    "                executor.submit(process_single_transcript_llamaindex, row, program)\n",
    "                for _, row in df.iterrows()\n",
    "            ]\n",
    "            \n",
    "            # Collect results\n",
    "            for future in futures:\n",
    "                success_result, error_result = future.result()\n",
    "                if success_result:\n",
    "                    successful_results.append(success_result)\n",
    "                if error_result:\n",
    "                    error_results.append(error_result)\n",
    "        \n",
    "        # Save successful results\n",
    "        if successful_results:\n",
    "            output_df = pd.DataFrame(successful_results)\n",
    "            output_df.to_csv(output_csv, index=False)\n",
    "            print(f\"‚úÖ Saved {len(successful_results)} processed transcripts to {output_csv}\")\n",
    "        \n",
    "        # Save error results\n",
    "        if error_results:\n",
    "            error_df = pd.DataFrame(error_results)\n",
    "            error_df.to_csv(error_csv, index=False)\n",
    "            print(f\"‚ö†Ô∏è Saved {len(error_results)} errors to {error_csv}\")\n",
    "        \n",
    "        print(f\"üìà Processing complete: {len(successful_results)} successful, {len(error_results)} errors\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Fatal error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage with LlamaIndex\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"../data/call_transcript_sample.csv\"\n",
    "    output_csv = \"../data/analyzed_calls_llamaindex.csv\"\n",
    "    error_csv = \"../data/processing_errors_llamaindex.csv\"\n",
    "    \n",
    "    parse_csv_with_llamaindex(input_csv, output_csv, error_csv, max_workers=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
