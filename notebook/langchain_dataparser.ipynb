{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Define Pydantic model for structured output\n",
    "class CallAnalysis(BaseModel):\n",
    "    \"\"\"Analysis results for a customer service call transcript.\"\"\"\n",
    "    transcript_summary: str = Field(description=\"Summary of the call transcript in 2-4 sentences\")\n",
    "    call_intent: str = Field(description=\"Main purpose or intention of the call\")\n",
    "    agents_performance_rating: int = Field(ge=1, le=5, description=\"Agent performance rating (1-5)\")\n",
    "    agents_performance_rating_rationale: str = Field(description=\"Rationale for agent performance rating\")\n",
    "    customer_sentiment_rating: int = Field(ge=1, le=5, description=\"Customer sentiment rating (1-5)\")\n",
    "    customer_sentiment_rationale: str = Field(description=\"Rationale for customer sentiment rating\")\n",
    "\n",
    "def process_single_transcript(row, llm, parser, prompt):\n",
    "    \"\"\"Process a single transcript row\"\"\"\n",
    "    conversation_id = row['conversation_id']\n",
    "    call_transcript = row['call_transcript']\n",
    "    \n",
    "    try:\n",
    "        # Create the chain with structured output\n",
    "        chain = prompt | llm | parser\n",
    "        \n",
    "        # Get structured response\n",
    "        result = chain.invoke({\"call_transcript\": call_transcript})\n",
    "        \n",
    "        # Create output row\n",
    "        output_row = {\n",
    "            'conversation_id': conversation_id,\n",
    "            'call_transcript': call_transcript,\n",
    "            'transcript_summary': result.transcript_summary,\n",
    "            'call_intent': result.call_intent,\n",
    "            'agents_performance_rating': result.agents_performance_rating,\n",
    "            'agents_performance_rating_rationale': result.agents_performance_rating_rationale,\n",
    "            'customer_sentiment_rating': result.customer_sentiment_rating,\n",
    "            'customer_sentiment_rationale': result.customer_sentiment_rationale,\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Processed conversation {conversation_id}\")\n",
    "        return output_row, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_row = {\n",
    "            'conversation_id': conversation_id,\n",
    "            'error_message': str(e),\n",
    "            'error_type': type(e).__name__,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        print(f\"‚ùå Error processing conversation {conversation_id}: {e}\")\n",
    "        return None, error_row\n",
    "\n",
    "def parse_csv_with_llm(input_csv: str, output_csv: str, error_csv: str, max_workers: int = 30):\n",
    "    \"\"\"\n",
    "    Parse CSV with LLM using structured outputs and concurrency\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to input CSV file\n",
    "        output_csv: Path to output CSV file  \n",
    "        error_csv: Path to error log CSV file\n",
    "        max_workers: Number of concurrent workers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize LLM and parser\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    parser = PydanticOutputParser(pydantic_object=CallAnalysis)\n",
    "    \n",
    "    # Create prompt with format instructions\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         \"\"\"You are an AI that analyzes call transcripts between customers and agents.\n",
    "         \n",
    "         Extract the following information:\n",
    "         - A 2-4 sentence summary of the call\n",
    "         - The main intent/purpose of the call\n",
    "         - Agent performance rating (1=very poor, 5=excellent)\n",
    "         - Rationale for agent rating\n",
    "         - Customer sentiment rating (1=very negative, 5=very positive)  \n",
    "         - Rationale for sentiment rating\n",
    "         \n",
    "         {format_instructions}\"\"\"),\n",
    "        (\"user\", \"Analyze this call transcript:\\n\\n{call_transcript}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "    \n",
    "    try:\n",
    "        # Read CSV with proper handling of quotes and line breaks\n",
    "        df = pd.read_csv(input_csv, quotechar='\"', escapechar='\\\\')\n",
    "        print(f\"Loaded {len(df)} transcripts to process\")\n",
    "        \n",
    "        # Process transcripts concurrently\n",
    "        successful_results = []\n",
    "        error_results = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            futures = [\n",
    "                executor.submit(process_single_transcript, row, llm, parser, prompt)\n",
    "                for _, row in df.iterrows()\n",
    "            ]\n",
    "            \n",
    "            # Collect results\n",
    "            for future in futures:\n",
    "                success_result, error_result = future.result()\n",
    "                if success_result:\n",
    "                    successful_results.append(success_result)\n",
    "                if error_result:\n",
    "                    error_results.append(error_result)\n",
    "        \n",
    "        # Save successful results\n",
    "        if successful_results:\n",
    "            output_df = pd.DataFrame(successful_results)\n",
    "            output_df.to_csv(output_csv, index=False)\n",
    "            print(f\"‚úÖ Saved {len(successful_results)} processed transcripts to {output_csv}\")\n",
    "        \n",
    "        # Save error results\n",
    "        if error_results:\n",
    "            error_df = pd.DataFrame(error_results)\n",
    "            error_df.to_csv(error_csv, index=False)\n",
    "            print(f\"‚ö†Ô∏è Saved {len(error_results)} errors to {error_csv}\")\n",
    "        \n",
    "        print(f\"üìà Processing complete: {len(successful_results)} successful, {len(error_results)} errors\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Fatal error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"../data/call_transcript_sample.csv\"\n",
    "    output_csv = \"../data/analyzed_calls_langchain.csv\"\n",
    "    error_csv = \"../data/processing_errors.csv\"\n",
    "    \n",
    "    parse_csv_with_llm(input_csv, output_csv, error_csv, max_workers=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
